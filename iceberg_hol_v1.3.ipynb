{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Iceberg Hands-on Lab Notebook\n",
				"\n",
				"This notebook creates an Iceberg table in the Glue Catalog database from the parquet files loaded into S3.\n",
				"It also provides a temaplate of how existing Glue Catalog Data Lake parquet tables can be converted to Iceberg format to be used directly with Snowflake."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"---"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Glue session configurations. \n",
				"\n",
				"Configure version and compute resources"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"%session_id_prefix iceberg-upgrade-add-files-\n",
				"%glue_version 4.0\n",
				"%idle_timeout 300\n",
				"%number_of_workers 2\n",
				"%worker_type G.1X\n",
				"%%configure \n",
				"{\n",
				"  \"--conf\": \"spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
				"  \"--datalake-formats\": \"iceberg\"\n",
				"}"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Variables for S3 bucket name, path, database and table names\n",
				"\n",
				"Enter the S3 bucket name that is used for this HOL - replace your-bucket-name with the S3 bucket name in your AWS account that is used for this HOL"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"bucket_name = \"your-bucket-name\" # your Amazon S3 bucket name for this HOL\n",
				"bucket_prefix = \"iceberg/quotes\" # path to parquet data\n",
				"catalog_name = \"glue_catalog\"\n",
				"database_name = \"iceberg_devday\"\n",
				"table_name = \"quotes\"\n",
				"file_path = f\"s3://{bucket_name}/{bucket_prefix}\""
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Configure S3 path and copy data files"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"import boto3\n",
				"s3 = boto3.client('s3')\n",
				"\n",
				"s3.put_object(Bucket=bucket_name, Key=(bucket_prefix+'/'))\n",
				"\n",
				"s3.copy_object(\n",
				"    Bucket=bucket_name, \n",
				"    CopySource='/snowflake-corp-se-workshop/VHOL_Iceberg_SNOW_AWS/data/quotes/snow_T3u4rF4p-cY_AGgidpZHvhc_0_2_002.parquet',\n",
				"    Key=(bucket_prefix+'/snow_T3u4rF4p-cY_AGgidpZHvhc_0_2_002.parquet')\n",
				")\n",
				"\n",
				"s3.copy_object(\n",
				"    Bucket=bucket_name, \n",
				"    CopySource='/snowflake-corp-se-workshop/VHOL_Iceberg_SNOW_AWS/data/quotes/snow_T3u4rF4p-cY_AGgidpZHvhc_0_2_004.parquet',\n",
				"    Key=(bucket_prefix+'/snow_T3u4rF4p-cY_AGgidpZHvhc_0_2_004.parquet')\n",
				")\n",
				"\n",
				"s3.copy_object(\n",
				"    Bucket=bucket_name, \n",
				"    CopySource='/snowflake-corp-se-workshop/VHOL_Iceberg_SNOW_AWS/data/quotes/snow_T3u4rF4p-cY_AGgidpZHvhc_0_2_006.parquet',\n",
				"    Key=(bucket_prefix+'/snow_T3u4rF4p-cY_AGgidpZHvhc_0_2_006.parquet')\n",
				")\n",
				"\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Create Glue Database"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "plaintext"
				}
			},
			"outputs": [],
			"source": [
				"glue = boto3.client(service_name='glue')\n",
				"\n",
				"glue.create_database(\n",
				"        \n",
				"    DatabaseInput={\n",
				"        'Name': database_name,\n",
				"        'Description': 'iceberg database'\n",
				"    }    \n",
				")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Initialize Spark Session"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql import SparkSession\n",
				"spark = SparkSession.builder \\\n",
				"    .config(f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
				"    .config(f\"spark.sql.catalog.{catalog_name}.warehouse\", file_path) \\\n",
				"    .config(f\"spark.sql.catalog.{catalog_name}.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\") \\\n",
				"    .config(f\"spark.sql.catalog.{catalog_name}.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
				"    .getOrCreate()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Check existing tables in the catalog/database"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"%%sql\n",
				"\n",
				"USE iceberg_devday"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"%%sql\n",
				"\n",
				"SHOW TABLES"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Create an Iceberg table from temporary view\n",
				"\n",
				"The view is used to workaround Spark DDL operations. \n",
				"This is not required if the tables already exist in the Glue Catalog, as you can simply reuse the DDL from the existing table with a CTAS LIMIT 0"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# Create temp view to generate DDL for Iceberg table\n",
				"# This step is not needed if using existing Glue Catalog tables or Glue Crawler - simplified for lab\n",
				"\n",
				"query = f\"\"\"\n",
				"create or replace temporary view temp_view_quotes as \n",
				"select\n",
				"    CAST ( 'a' AS VARCHAR(100)) AS UUID ,\n",
				"    CAST ( 'a' AS VARCHAR(32)) AS BATCHID ,\n",
				"    CAST ( 'a' AS VARCHAR(100)) AS QUOTE_PRODUCT ,\n",
				"    CAST ( '2024-01-01' AS DATE) AS QUOTEDATE,\n",
				"    CAST ( 1 AS DECIMAL(38,0)) AS QUOTEHOUR ,\n",
				"    CAST ( 'a' AS VARCHAR(50)) AS POLICYNO ,\n",
				"    CAST ( '2024-01-01' AS DATE) AS INCEPTIONDATE ,\n",
				"    CAST ( '2024-01-01' AS DATE) AS EXPIRYDATE ,\n",
				"    CAST ( '2024-01-01' AS DATE) AS EFFECTIVESTARTDATE ,\n",
				"    CAST ( '2024-01-01' AS DATE) AS EFFECTIVEENDDATE ,\n",
				"    CAST ( 'a' AS VARCHAR(20)) AS PREVINSR ,\n",
				"    CAST ( 'a' AS VARCHAR(20)) AS CREDITCHECKSCONSENTIND ,\n",
				"    CAST ( 1 AS DECIMAL(38,0)) AS CREDITSCORE ,\n",
				"    CAST ( 'a' AS VARCHAR(100)) AS DATEOFBIRTH ,\n",
				"    CAST ( 'a' AS VARCHAR(20)) AS HOMEOWNERIND ,\n",
				"    CAST ( 'a' AS VARCHAR(20)) AS MARITALSTATUS ,\n",
				"    CAST ( 1 AS DECIMAL(38,0)) AS VEHICLESAVAILABLE ,\n",
				"    CAST ( 'a' AS VARCHAR(20)) AS PRN ,\n",
				"    CAST ( 'a' AS VARCHAR(20)) AS SEX ,\n",
				"    CAST ( 'a' AS VARCHAR(100)) AS POSTCODEDISTRICT ,\n",
				"    CAST ( 'a' AS VARCHAR(100)) AS POSTCODEFULL ,\n",
				"    CAST ( 'a' AS VARCHAR(100)) AS POSTCODESECTOR ,\n",
				"    CAST ( 'a' AS VARCHAR(100)) AS SURNAME ,\n",
				"    CAST ( 1 AS DECIMAL(28,2)) AS IPTAMOUNT ,\n",
				"    CAST ( 1 AS DECIMAL(28,2)) AS NEWRISKPREMIUM ,\n",
				"    CAST ( 1 AS DECIMAL(28,2)) AS OLDRISKPREMIUM ,\n",
				"    CAST ( 1 AS DECIMAL(28,2)) AS ORIGINALPREMIUM ,\n",
				"    CAST ( 1 AS DECIMAL(28,2)) AS PREMIUMINCLIPT ,\n",
				"    CAST ( 1 AS DECIMAL(28,2)) AS PREMIUMEXCLIPT ,\n",
				"    CAST ( 1 AS DECIMAL(28,2)) AS TOTALPREMIUMPAYABLE ,\n",
				"    CAST ( 'a' AS VARCHAR(25)) AS AGENCYREF ,\n",
				"    CAST ( 'a' AS VARCHAR(25)) AS BUSINESSSOURCECODE ,\n",
				"    CAST ( 'a' AS VARCHAR(25)) AS INTERMEDIARY_CODE ,\n",
				"    CAST ( 'a' AS VARCHAR(25)) AS INSRPMTTYPE ,\n",
				"    CAST ( 1 AS DECIMAL(38,0)) AS DEBITFRQCY ,\n",
				"    CAST ( 'a' AS VARCHAR(250)) AS ADDRESS ,\n",
				"    CAST ( 'a' AS VARCHAR(250)) AS FULLNAME ,\n",
				"    CAST ( 'a' AS VARCHAR(250)) AS POSTCODE ,\n",
				"    CAST ( 'a' AS VARCHAR(250)) AS PHONENUMBER ,\n",
				"    CAST ( 'a' AS VARCHAR(511)) AS EMAIL \n",
				"\n",
				"\"\"\"\n",
				"spark.sql(query)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# Create empty Iceberg table usign DDL from parquet table with temp view\n",
				"\n",
				"query = f\"\"\"\n",
				"CREATE OR REPLACE TABLE {catalog_name}.{database_name}.{table_name} \n",
				"USING iceberg\n",
				"AS SELECT * FROM temp_view_quotes LIMIT 0\n",
				"\n",
				"\n",
				"\"\"\"\n",
				"spark.sql(query)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"%%sql\n",
				"\n",
				"SHOW TABLES"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Execute add_files procedure\n",
				"\n",
				"Use add_files to add the parquest files to the created Iceberg table. This allows you to leverage Iceberg format without the need to rewrite the underlying data files. Can be very handy to convert existing Data Lake tables to Iceberg format."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"query = f\"\"\"\n",
				"CALL {catalog_name}.system.add_files(table => '{database_name}.{table_name}', source_table => '`parquet`.`{file_path}`')\n",
				"\"\"\"\n",
				"\n",
				"spark.sql(query).show(truncate=False)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Check the data files which belong to the Iceberg table\n",
				"\n",
				"Notice that the data file path is still pointing to the original path where Parquet files are residing. Therefore, no change in the path"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"query = f\"\"\"\n",
				"SELECT file_path FROM {catalog_name}.{database_name}.{table_name}.files\n",
				"\"\"\"\n",
				"\n",
				"spark.sql(query).show(10, truncate=False)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Check new metadata files\n",
				"\n",
				"These files will be available in the Glue Catalog directory set above. This path is pointing to a separate folder under the S3 bucket, where only the metedata files resides"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"query = f\"\"\"\n",
				"SELECT snapshot_id, manifest_list FROM {catalog_name}.{database_name}.{table_name}.snapshots\n",
				"\"\"\"\n",
				"\n",
				"spark.sql(query).show(10, truncate=False)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Stop session"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"%stop_session"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
